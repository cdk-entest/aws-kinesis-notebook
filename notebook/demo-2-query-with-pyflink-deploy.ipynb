{
  "metadata": {
    "name": "Demo 2 Query with PyFlink and Deploy",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Create a In-Memory Table"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.pyflink\ninput_table_name \u003d \"stock_input_table\"\noutput_table_name \u003d \"stock_output_table\"\nbucket_name \u003d \"data-lake-demo-17072023\"\nregion \u003d \"ap-southeast-1\"\ninput_stream_name \u003d \"stock-input-stream\"\nprefix \u003d \"stock-data\""
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.pyflink\nst_env.execute_sql(\"\"\"DROP TABLE IF EXISTS {0}\"\"\".format(input_table_name))\nst_env.execute_sql(\"\"\"DROP TABLE IF EXISTS {0}\"\"\".format(output_table_name))"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.pyflink\nst_env.execute_sql(\"\"\"\nCREATE TABLE {0} (\n                ticker VARCHAR(6),\n                price DOUBLE,\n                event_time TIMESTAMP(3),\n                WATERMARK FOR event_time AS event_time - INTERVAL \u00275\u0027 SECOND\n\n              )\n              PARTITIONED BY (ticker)\n              WITH (\n                \u0027connector\u0027 \u003d \u0027kinesis\u0027,\n                \u0027stream\u0027 \u003d \u0027{1}\u0027,\n                \u0027aws.region\u0027 \u003d \u0027{2}\u0027,\n                \u0027scan.stream.initpos\u0027 \u003d \u0027LATEST\u0027,\n                \u0027format\u0027 \u003d \u0027json\u0027,\n                \u0027json.timestamp-format.standard\u0027 \u003d \u0027ISO-8601\u0027\n              ) \"\"\".format(input_table_name, input_stream_name, region))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n## Enable Checkpointing"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.pyflink\nst_env.get_config().get_configuration().set_string(\n    \"execution.checkpointing.interval\", \"1min\"\n)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n## Writing Results to Amazon S3"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.pyflink\nst_env.execute_sql(\"\"\"CREATE TABLE {0} (\n                ticker VARCHAR(6),\n                price DOUBLE,\n                event_time TIMESTAMP(3)\n              )\n              PARTITIONED BY (ticker)\n              WITH (\n                  \u0027connector\u0027\u003d\u0027filesystem\u0027,\n                  \u0027path\u0027\u003d\u0027s3a://{1}/{2}/\u0027,\n                  \u0027format\u0027\u003d\u0027csv\u0027,\n                  \u0027sink.partition-commit.policy.kind\u0027\u003d\u0027success-file\u0027,\n                  \u0027sink.partition-commit.delay\u0027 \u003d \u00271 min\u0027\n              )\"\"\".format(output_table_name, bucket_name, prefix))"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%flink.pyflink\ntable_result \u003d st_env.execute_sql(\"INSERT INTO {0} SELECT * FROM {1}\".format(output_table_name, input_table_name))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "table_result.get_job_client().cancel()"
    }
  ]
}